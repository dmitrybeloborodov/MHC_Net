{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (\n",
    "    print_function,\n",
    "    division,\n",
    "    absolute_import,\n",
    ")\n",
    "import collections\n",
    "from copy import copy\n",
    "\n",
    "import pandas\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_SYMOLS = ['A', 'R', 'N', 'D', 'C',\n",
    "             'Q', 'E', 'G', 'H', 'I',\n",
    "             'L', 'K', 'M', 'F', 'P',\n",
    "             'S', 'T', 'W', 'Y', 'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ligand(ligand):\n",
    "    m = list()\n",
    "    for symbol in AA_SYMOLS:\n",
    "        channel = list()\n",
    "        for aa in ligand:\n",
    "            if aa.upper() == symbol: channel.append(1.0)\n",
    "            else: channel.append(random.uniform(0.001, 0.01))\n",
    "        m.append(channel)\n",
    "    m = np.array(m).reshape(1, len(ligand), 20)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00712255 0.00147424 0.00173254 0.00733454 0.00486762 0.00701955\n",
      "   0.00566584 0.00993252 0.00538337 0.00690312 0.00698338 0.00783121\n",
      "   0.00554433 0.00109508 0.00335705 0.00770352 0.00652109 0.00372498\n",
      "   0.00875786 0.0030225 ]\n",
      "  [0.00824988 0.00887811 0.005264   0.00918274 0.00145545 0.00300292\n",
      "   0.00728582 0.00526036 0.00332123 0.00212888 0.00572468 0.00127711\n",
      "   0.00199793 0.00859027 0.00207352 0.00658875 0.00180687 0.00579378\n",
      "   0.00896766 0.00684221]\n",
      "  [0.00646873 0.0013779  0.00171367 0.00554197 0.00159154 0.0081159\n",
      "   0.00977888 0.00449383 0.0086963  0.00308931 0.0089887  0.00509944\n",
      "   0.0086759  0.00493609 0.00663178 0.00497767 0.00415516 1.\n",
      "   0.0039738  0.00910814]\n",
      "  [0.00556365 0.00915135 0.00119691 0.00852738 0.00542975 0.00541686\n",
      "   0.00715161 0.00835746 0.00932109 0.00697007 0.00361128 1.\n",
      "   0.00754489 0.00179376 0.00252989 0.00949418 0.00328642 0.00428285\n",
      "   0.00767927 0.00852271]\n",
      "  [0.0048442  0.00790229 0.00555354 0.00199327 0.00215958 0.00234197\n",
      "   0.00987413 0.008624   0.00552964 0.00761992 0.00126392 0.0098827\n",
      "   0.00161649 0.00680281 0.00265016 0.00295873 0.00829    0.00854418\n",
      "   0.00697063 1.        ]\n",
      "  [0.00592812 0.00841669 0.00422633 0.00775101 0.00622593 0.00389045\n",
      "   1.         0.00608421 0.00191085 1.         0.0054368  0.00959385\n",
      "   0.00640687 0.00695614 0.00232471 0.00895939 0.00431021 0.00722419\n",
      "   0.00465809 0.00165368]\n",
      "  [0.00645946 0.00714946 0.00790365 1.         0.00237457 0.00642918\n",
      "   0.00875012 0.00335696 0.00776966 0.00544278 0.00488747 0.00603721\n",
      "   0.00889792 0.00997821 0.00261986 0.0087475  0.00423329 0.00416751\n",
      "   0.00574482 0.00514469]\n",
      "  [0.00380463 0.00427791 0.00911224 0.0048175  0.00975737 0.00849633\n",
      "   0.00178543 0.00353234 0.00413099 0.00910775 0.00903129 0.00796352\n",
      "   0.00241118 0.00940278 0.00339121 0.00847501 0.00474671 0.00167764\n",
      "   0.00343448 0.00468928]\n",
      "  [0.00780932 0.00470272 0.00348507 0.0092789  1.         0.00682371\n",
      "   1.         0.00405028 0.00583588 0.00531778 0.00681601 0.00682348\n",
      "   0.00292421 0.00421269 0.00394059 0.00958559 1.         0.00808406\n",
      "   0.00219945 0.00445456]]]\n"
     ]
    }
   ],
   "source": [
    "print(encode_ligand('KMYEYVFKG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_AMINO_ACIDS = collections.OrderedDict(sorted({\n",
    "    \"A\": \"Alanine\",\n",
    "    \"R\": \"Arginine\",\n",
    "    \"N\": \"Asparagine\",\n",
    "    \"D\": \"Aspartic Acid\",\n",
    "    \"C\": \"Cysteine\",\n",
    "    \"E\": \"Glutamic Acid\",\n",
    "    \"Q\": \"Glutamine\",\n",
    "    \"G\": \"Glycine\",\n",
    "    \"H\": \"Histidine\",\n",
    "    \"I\": \"Isoleucine\",\n",
    "    \"L\": \"Leucine\",\n",
    "    \"K\": \"Lysine\",\n",
    "    \"M\": \"Methionine\",\n",
    "    \"F\": \"Phenylalanine\",\n",
    "    \"P\": \"Proline\",\n",
    "    \"S\": \"Serine\",\n",
    "    \"T\": \"Threonine\",\n",
    "    \"W\": \"Tryptophan\",\n",
    "    \"Y\": \"Tyrosine\",\n",
    "    \"V\": \"Valine\",\n",
    "}.items()))\n",
    "COMMON_AMINO_ACIDS_WITH_UNKNOWN = copy(COMMON_AMINO_ACIDS)\n",
    "COMMON_AMINO_ACIDS_WITH_UNKNOWN[\"X\"] = \"Unknown\"\n",
    "\n",
    "AMINO_ACID_INDEX = dict(\n",
    "    (letter, i) for (i, letter) in enumerate(COMMON_AMINO_ACIDS_WITH_UNKNOWN))\n",
    "\n",
    "AMINO_ACIDS = list(COMMON_AMINO_ACIDS_WITH_UNKNOWN.keys())\n",
    "\n",
    "BLOSUM62_MATRIX = pandas.read_csv(StringIO(\"\"\"\n",
    "   A  R  N  D  C  Q  E  G  H  I  L  K  M  F  P  S  T  W  Y  V  X\n",
    "A  4 -1 -2 -2  0 -1 -1  0 -2 -1 -1 -1 -1 -2 -1  1  0 -3 -2  0  0\n",
    "R -1  5  0 -2 -3  1  0 -2  0 -3 -2  2 -1 -3 -2 -1 -1 -3 -2 -3  0\n",
    "N -2  0  6  1 -3  0  0  0  1 -3 -3  0 -2 -3 -2  1  0 -4 -2 -3  0\n",
    "D -2 -2  1  6 -3  0  2 -1 -1 -3 -4 -1 -3 -3 -1  0 -1 -4 -3 -3  0\n",
    "C  0 -3 -3 -3  9 -3 -4 -3 -3 -1 -1 -3 -1 -2 -3 -1 -1 -2 -2 -1  0\n",
    "Q -1  1  0  0 -3  5  2 -2  0 -3 -2  1  0 -3 -1  0 -1 -2 -1 -2  0\n",
    "E -1  0  0  2 -4  2  5 -2  0 -3 -3  1 -2 -3 -1  0 -1 -3 -2 -2  0\n",
    "G  0 -2  0 -1 -3 -2 -2  6 -2 -4 -4 -2 -3 -3 -2  0 -2 -2 -3 -3  0\n",
    "H -2  0  1 -1 -3  0  0 -2  8 -3 -3 -1 -2 -1 -2 -1 -2 -2  2 -3  0\n",
    "I -1 -3 -3 -3 -1 -3 -3 -4 -3  4  2 -3  1  0 -3 -2 -1 -3 -1  3  0\n",
    "L -1 -2 -3 -4 -1 -2 -3 -4 -3  2  4 -2  2  0 -3 -2 -1 -2 -1  1  0\n",
    "K -1  2  0 -1 -3  1  1 -2 -1 -3 -2  5 -1 -3 -1  0 -1 -3 -2 -2  0\n",
    "M -1 -1 -2 -3 -1  0 -2 -3 -2  1  2 -1  5  0 -2 -1 -1 -1 -1  1  0\n",
    "F -2 -3 -3 -3 -2 -3 -3 -3 -1  0  0 -3  0  6 -4 -2 -2  1  3 -1  0\n",
    "P -1 -2 -2 -1 -3 -1 -1 -2 -2 -3 -3 -1 -2 -4  7 -1 -1 -4 -3 -2  0\n",
    "S  1 -1  1  0 -1  0  0  0 -1 -2 -2  0 -1 -2 -1  4  1 -3 -2 -2  0\n",
    "T  0 -1  0 -1 -1 -1 -1 -2 -2 -1 -1 -1 -1 -2 -1  1  5 -2 -2  0  0 \n",
    "W -3 -3 -4 -4 -2 -2 -3 -2 -2 -3 -2 -3 -1  1 -4 -3 -2 11  2 -3  0\n",
    "Y -2 -2 -2 -3 -2 -1 -2 -3  2 -1 -1 -2 -1  3 -3 -2 -2  2  7 -1  0\n",
    "V  0 -3 -3 -3 -1 -2 -2 -3 -3  3  1 -2  1 -1 -2 -2  0 -3 -1  4  0\n",
    "X  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
    "\"\"\"), sep='\\s+').loc[AMINO_ACIDS, AMINO_ACIDS]\n",
    "assert (BLOSUM62_MATRIX == BLOSUM62_MATRIX.T).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>...</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  C  D  E  F  G  H  I  K  L ...  N  P  Q  R  S  T  V  W  Y  X\n",
       "A  4  0 -2 -1 -2  0 -2 -1 -1 -1 ... -2 -1 -1 -1  1  0  0 -3 -2  0\n",
       "C  0  9 -3 -4 -2 -3 -3 -1 -3 -1 ... -3 -3 -3 -3 -1 -1 -1 -2 -2  0\n",
       "D -2 -3  6  2 -3 -1 -1 -3 -1 -4 ...  1 -1  0 -2  0 -1 -3 -4 -3  0\n",
       "E -1 -4  2  5 -3 -2  0 -3  1 -3 ...  0 -1  2  0  0 -1 -2 -3 -2  0\n",
       "F -2 -2 -3 -3  6 -3 -1  0 -3  0 ... -3 -4 -3 -3 -2 -2 -1  1  3  0\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLOSUM62_MATRIX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with h = 1\n",
      "Model built with h = 2\n",
      "Model built with h = 3\n",
      "Model built with h = 4\n",
      "Model built with h = 5\n",
      "epoch [0/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 5.47783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [100/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.25934\n",
      "epoch [200/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.25034\n",
      "epoch [300/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.24352\n",
      "epoch [400/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.23554\n",
      "epoch [500/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.22473\n",
      "epoch [600/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.21042\n",
      "epoch [700/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.19263\n",
      "epoch [800/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.17207\n",
      "epoch [900/900]\n",
      "    model 0 loss 3.02213\n",
      "    model 1 loss 1.02515\n",
      "    model 2 loss 10.39546\n",
      "    model 3 loss 4.01103\n",
      "    model 4 loss 0.21481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0478],\n",
       "         [ 0.0478],\n",
       "         [ 0.0478],\n",
       "         ...,\n",
       "         [ 0.0478],\n",
       "         [ 0.0478],\n",
       "         [ 0.0478]],\n",
       "\n",
       "        [[ 0.2937],\n",
       "         [ 0.2937],\n",
       "         [ 0.2937],\n",
       "         ...,\n",
       "         [ 0.3529],\n",
       "         [ 0.3531],\n",
       "         [ 0.3533]],\n",
       "\n",
       "        [[-0.5085],\n",
       "         [-0.5084],\n",
       "         [-0.5082],\n",
       "         ...,\n",
       "         [-0.3368],\n",
       "         [-0.3365],\n",
       "         [-0.3363]],\n",
       "\n",
       "        [[-0.0301],\n",
       "         [-0.0302],\n",
       "         [-0.0303],\n",
       "         ...,\n",
       "         [-0.0566],\n",
       "         [-0.0567],\n",
       "         [-0.0567]],\n",
       "\n",
       "        [[ 0.5331],\n",
       "         [ 0.5336],\n",
       "         [ 0.5340],\n",
       "         ...,\n",
       "         [ 0.3529],\n",
       "         [ 0.3520],\n",
       "         [ 0.3511]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "#a = torch.randn(5, 2)\n",
    "\n",
    "# params\n",
    "n_ex = 10\n",
    "nets = 5\n",
    "epochs = 1000\n",
    "samples = 100\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_train = Variable(torch.rand(n_ex, 1), requires_grad=False)\n",
    "y_train = Variable(torch.rand(n_ex, 1), requires_grad=False)\n",
    "\n",
    "netlist = []\n",
    "params = []\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super(MLP, self).__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(1, h),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(h, h),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(h, 1),\n",
    "                    torch.nn.Tanh()\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "for i in range(1, nets+1):\n",
    "    h = i\n",
    "    print('Model built with h =', h)\n",
    "    netlist.append(MLP(h))\n",
    "params += list(netlist[i-1].parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD(params, 0.03)\n",
    "crit = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss_list = []\n",
    "    for net in netlist:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(x_train)\n",
    "        loss = crit(out, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    if i % samples == 0:\n",
    "        print('epoch [{}/{}]'.format(i, epochs-samples))\n",
    "        for j, model in enumerate(netlist):\n",
    "            print('    model {} loss {:.5f}'.format(j, loss_list[j]))\n",
    "\n",
    "# x data for plotting\n",
    "xdata = Variable(torch.arange(0, 0.999, 0.001).unsqueeze_(1))\n",
    "pred = torch.Tensor(nets, xdata.size(0), 1)\n",
    "xdata_plot = xdata.data.numpy()\n",
    "\n",
    "# get predictions for each network on 1000 x values (xdata)\n",
    "for i, net in enumerate(netlist):\n",
    "    pred[i] = net(xdata)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
